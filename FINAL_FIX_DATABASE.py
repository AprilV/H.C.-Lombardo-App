#!/usr/bin/env python3
"""
FINAL FIX: Complete schema rebuild of Render database
This will MIRROR the local database exactly
"""

import psycopg2
from psycopg2.extras import execute_values
import sys

RENDER_URL = "postgresql://nfl_user:rzkKyzQq9pTas14pXDJU3fm8cCZObAh5@dpg-d4j30ah5pdvs739551m0-a.oregon-postgres.render.com/nfl_analytics"

print("\n" + "="*80)
print("üîß FINAL DATABASE REBUILD - COMPLETE SCHEMA MIGRATION")
print("="*80)
print("\nThis will:")
print("  1. DROP team_game_stats on Render")
print("  2. Recreate with LOCAL schema (64 columns including EPA)")
print("  3. Copy ALL 14,398 records from local")
print("  4. Verify everything works")

response = input("\n‚ö†Ô∏è  Type 'YES' to proceed: ")
if response != 'YES':
    print("‚ùå Aborted")
    sys.exit(1)

# Connect to both databases
local_conn = psycopg2.connect(
    dbname='nfl_analytics',
    user='postgres',
    password='aprilv120',
    host='localhost',
    port='5432'
)

render_conn = psycopg2.connect(RENDER_URL)
render_cur = render_conn.cursor()
local_cur = local_conn.cursor()

print("\nüìã STEP 1: Extract schema from LOCAL database")
print("-"*80)

# Get CREATE TABLE statement by extracting columns
local_cur.execute("""
    SELECT column_name, data_type, character_maximum_length, is_nullable
    FROM information_schema.columns
    WHERE table_schema = 'hcl' AND table_name = 'team_game_stats'
    ORDER BY ordinal_position
""")

columns = local_cur.fetchall()
print(f"‚úÖ Found {len(columns)} columns in local team_game_stats")

# Build CREATE TABLE statement
create_sql = "CREATE TABLE hcl.team_game_stats (\n"
col_defs = []

for col_name, data_type, max_len, nullable in columns:
    # Map PostgreSQL types
    if data_type == 'integer':
        col_type = 'INTEGER'
    elif data_type == 'double precision':
        col_type = 'DOUBLE PRECISION'
    elif data_type == 'boolean':
        col_type = 'BOOLEAN'
    elif data_type == 'text':
        col_type = 'TEXT'
    elif data_type == 'date':
        col_type = 'DATE'
    elif data_type == 'timestamp with time zone':
        col_type = 'TIMESTAMP WITH TIME ZONE'
    elif data_type == 'timestamp without time zone':
        col_type = 'TIMESTAMP'
    elif data_type == 'character varying':
        col_type = f'VARCHAR({max_len})' if max_len else 'VARCHAR'
    else:
        col_type = data_type.upper()
    
    null_constraint = '' if nullable == 'YES' else ' NOT NULL'
    col_defs.append(f"    {col_name} {col_type}{null_constraint}")

create_sql += ",\n".join(col_defs)
create_sql += "\n);"

print("\nüìã STEP 2: DROP existing table on Render")
print("-"*80)

render_cur.execute("DROP TABLE IF EXISTS hcl.team_game_stats CASCADE")
render_conn.commit()
print("‚úÖ Dropped old table")

print("\nüìã STEP 3: CREATE new table with correct schema")
print("-"*80)

render_cur.execute(create_sql)
render_conn.commit()
print(f"‚úÖ Created table with {len(columns)} columns")

print("\nüìã STEP 4: Copy ALL data from local to Render")
print("-"*80)

# Get column names
col_names = [col[0] for col in columns]

# Fetch all data from local
local_cur.execute(f"SELECT {', '.join(col_names)} FROM hcl.team_game_stats ORDER BY season, week, game_id")
all_data = local_cur.fetchall()

print(f"‚úÖ Fetched {len(all_data):,} records from local")

# Insert into Render in batches
batch_size = 500
for i in range(0, len(all_data), batch_size):
    batch = all_data[i:i+batch_size]
    execute_values(
        render_cur,
        f"INSERT INTO hcl.team_game_stats ({', '.join(col_names)}) VALUES %s",
        batch
    )
    render_conn.commit()
    print(f"  ‚Üí Inserted batch {i//batch_size + 1}/{(len(all_data)-1)//batch_size + 1}")

print(f"‚úÖ Copied {len(all_data):,} records")

print("\nüìã STEP 5: Verify data")
print("-"*80)

# Check counts
render_cur.execute("SELECT COUNT(*) FROM hcl.team_game_stats")
total = render_cur.fetchone()[0]

render_cur.execute("SELECT COUNT(*) FROM hcl.team_game_stats WHERE season = 2025")
count_2025 = render_cur.fetchone()[0]

render_cur.execute("SELECT COUNT(*) FROM hcl.team_game_stats WHERE season = 2025 AND week = 13")
count_wk13 = render_cur.fetchone()[0]

render_cur.execute("""
    SELECT COUNT(*) as total, COUNT(epa_per_play) as with_epa
    FROM hcl.team_game_stats WHERE season = 2025
""")
epa_check = render_cur.fetchone()

print(f"‚úÖ Total records: {total:,}")
print(f"‚úÖ 2025 season: {count_2025:,}")
print(f"‚úÖ Week 13: {count_wk13}")
print(f"‚úÖ 2025 with EPA: {epa_check[1]:,} / {epa_check[0]:,}")

# Sample data
render_cur.execute("""
    SELECT game_id, team, points, epa_per_play, pass_epa, rush_epa
    FROM hcl.team_game_stats
    WHERE season = 2025 AND week = 13
    LIMIT 3
""")

print("\nüìä Sample Week 13 data:")
for row in render_cur.fetchall():
    print(f"  {row[0]:20} | {row[1]:3} | pts:{row[2]:2} | epa:{row[3]:.3f} | pass_epa:{row[4]:.2f} | rush_epa:{row[5]:.2f}")

local_conn.close()
render_conn.close()

print("\n" + "="*80)
print("‚úÖ DATABASE REBUILD COMPLETE!")
print("="*80)
print("\nüéØ What's fixed:")
print("  ‚úÖ team_game_stats has ALL 64 columns (was 51)")
print("  ‚úÖ ALL EPA columns present and populated")
print("  ‚úÖ Week 13 games ready for ML predictions")
print("  ‚úÖ Complete 1999-2025 dataset (14,398 records)")
print("\n" + "="*80 + "\n")
